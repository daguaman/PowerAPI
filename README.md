# PowerAPI
PowerAPICloud
Implementación de la arquitectura de PowerAPI en un entorno dockerizado para estimar el consumo energético de aplicaciones de software

## Green Software
A lo largo de los años se le ha dado cada vez más importancia al concepto de Green IT, por ser considerado uno de los factores más importantes para combatir el problema mundial del medioambiente. Dicho concepto, al que también se le puede referir como Green Computing, se define como el estudio de diseñar, transformar y crear tecnología usando recursos informáticos sostenibles desde el punto de vista medioambiental.

(Murugesan, 2012) exponen que green software es todo software que es amigable con el medio ambiente. Para que el software se considere green, este debe enfocarse en reducir el impacto ambiental y que consuma menos energía, lo que se puede lograr mejorando la gestión de los recursos y procesamiento de datos. (Biswas, 2021) mencionan que para el desarrollo de software green es necesario comprender el comportamiento del consumo energético de las aplicaciones dentro de todo tipo de dispositivos, esto se traduce en que una mejora en la forma de desarrollar las aplicaciones ayuda a optimizar el consumo energético de las mismas. (Taina, 2011) expone que dentro del software green también se ven implicadas todas las fases del desarrollo por lo tanto es importante que estos procesos también ayuden en el desarrollo del software verde. 

(Naumann, 2013) definen al green software, como aquel que tiene un impacto mucho más bajo con respecto al software desarrollado de manera tradicional. Dicho impacto puede ser económicos, ambientales, sociales. (Calero, 2015) exponen que, para hablar de factores de calidad de software, es necesario tener en cuenta dos puntos de vista, por un lado TIC’s ‘verdes’, que se refiere a que la infraestructura de hardware debe ser energéticamente eficiente, es decir que no existan componentes que tengan un excesivo consumo energético o que los componentes sean obsoletos, ya que generan ineficiencia energética. Y como segundo punto de vista que la ingeniería para el desarrollo de software sea sostenible, es decir que durante toda la fase de desarrollo de las aplicaciones se tenga en cuenta el consumo energético, esto con la finalidad que desde la concepción del producto se tenga en cuenta enfoques más sostenibles energéticamente.

En un estudio realizado por (Calero C. B., 2013), se expone que los factores de calidad preexistentes, ya sea del producto o sobre el uso del producto, pueden servir como base para el software verde, ya que se añaden sub características de sostenibilidad, dichas sub características sirven de apoyo a las organizaciones que deseen implementar factores de calidad para el desarrollo de software verde. 

(Li, 2014) exponen tres aspectos importantes consumo de la red, consumo de memoria y prácticas de programación a bajo nivel, que según los autores, son temas de fácil implementación, ya que generalmente no llegan a hacer cambios de alto nivel, sino que todo queda a disposición del desarrollador para su implementación en código. Además, mencionan que estos tres aspectos tienen un alto impacto en el consumo energético en smartphones, por lo que la implementación de buenas prácticas de software verde sería de gran utilidad.

Una de las principales buenas prácticas es la implementación de “Requerimientos Ambientales”, principalmente utilizados como criterio de posibles requerimientos no funcionales, estos requerimientos deben ser presentados a los stakeholders del proyecto para que este dé su visto bueno   (Agarwal, 2012) . Otra buena práctica expuesta en  (Steigerwald, 2012) menciona que el desarrollo de multithreading o multihilo, es una práctica que generalmente en desarrolladores novatos no se utiliza  mucho debido a su nivel de complejidad, pero al igual que la elección de un algoritmo optimo, aporta mucho al desarrollo de cualquier solución de software, esto debido a que se aprovecha una característica muy importante del procesador como lo es la ejecución de múltiples hilos de ejecución, para así reducir el tiempo de ejecución notablemente, por ejemplo en vez de enviar transacción por transacción a una base de datos, se puede adecuar al software para que mediante el multithreading ejecute estos procesos de manera conjunta, algo que sin lugar a duda reducirá el tiempo de ejecución de cualquier tipo de software notoriamente.

Dentro del proceso de desarrollo también interviene la infraestructura de TI, para ello en  (Pazowski, 2015) se exponen 10 buenas prácticas para infraestructura de TI verde, en donde algunas de estas buenas prácticas pueden ser llevadas al campo del software. Dado que el software verde tiene un amplio rango de temas que se deben abordar, las cuales van desde las métricas, hasta su implementación dentro de la ingeniería de software, es necesario analizar qué beneficios conllevan su implementación, ya que estos beneficios pueden significar un punto de inflexión en su implementación o no, dentro de las organizaciones.
## Green Cloud
Green Cloud se presenta como una solución sostenible para reducir las demandas energéticas de los centros de datos albergando sus servicios en la nube, lo que permite aportar menos inversión económica y más eficiencia energética. La estrategia de muchas empresas hacia el Green IT es adoptar como primer paso la migración a la nube, pues entre el 80% y el 90% de las empresas ya han adoptado esta medida en alguno de sus servicios (Jain, 2013) . La cual primero conlleva el proceso de trasladar las operaciones de almacenamiento, procesamiento y ejecución de programas desde los entornos locales o instalaciones físicas de una organización, hacia servicios en la nube o servidores remotos como pueden ser Amazon Web Services (AWS), Microsoft Azure o Google Cloud Platform.

Los servicios en la nube suelen reducir el consumo de energía en comparación por ejemplo con los centros de datos locales porque tienen menos gastos generales y más eficiencia en la escalabilidad. Según (Verdecchia, 2021) entre el 80% y el 90% de los negocios ya han migrado a la nube. Al reemplazar la funcionalidad local con servicios nativos en la nube, la selección de servicios debe basarse en indicadores transparentes (que deben proporcionar los proveedores de servicios en la nube) para la eficiencia energética y recursos relacionados. 

La computación en la nube significa la prestación de servicios a través de Internet. Infraestructura como servicio (IaaS), plataforma como servicio (PaaS) y el software como servicio (SaaS) son tres tipos de servicios proporcionados por la computación en la nube  (Beik, 2012) La computación en la nube ha traído una transformación radical en la prestación y consumo de servicios digitales. Gracias a sus arquitecturas de alto rendimiento, esta tecnología permite ofrecer una amplia gama de servicios a los usuarios de forma más eficiente y escalable. No obstante, es importante destacar que la computación en la nube también implica un consumo significativo de recursos, que abarca desde el uso de servidores de alto rendimiento hasta unidades de almacenamiento, sistemas de enfriamiento y otros componentes de infraestructura que requieren una considerable cantidad de energía.

La capa consciente de la energía en la arquitectura de software propuesta por (Beik R. , 2012) conlleva soluciones tanto de software como de hardware. En soluciones de software, la virtualización es una de las mejores tecnologías para el consumo eficiente de energía en centros de datos.

## Trabajos relacionados
(Newman, 2019) define a los microservicios como pequeños servicios autónomos que trabajan juntos, que se puede implementar, escalar y probar de forma independiente. Microservicios son servicios autónomos que funcionan en conjunto y se encargan de solucionar una parte del trabajo.  (Esposito, 2016) define la arquitectura de microservicio como un patrón de diseño de aplicaciones que se despliegan en la nube que implica que la aplicación se divida en una serie de pequeños servicios independientes, cada uno de los cuales es responsable de la implementación de una determinada característica. Microservicios funcionan independientemente de otro, por lo tanto, si un microservicio falla, este no afecta al rendimiento de los demás (Larrucea, 2018). (Araújo, 2023) en su trabajo expone sobre los factores que influyen en el consumo de energía en arquitecturas de microservicios y proporciona información sobre posibles soluciones para mejorar la eficiencia energética. Entre los factores constan los factores arquitectónicos, factores de implementación y factores de carga de trabajo. Los autores mencionan que, las arquitecturas de microservicios pueden tener un impacto complejo en el consumo de energía, debido a que, si bien ofrecen beneficios potenciales como mayor escalabilidad y agilidad, también pueden introducir inconvenientes como un mayor tráfico de red y gastos generales de monitoreo, lo que lleva a un mayor consumo de energía. En el artículo se identifican varias áreas de investigación relacionadas con el consumo de energía en microservicios entre las que destacan estrategias de implementación que tengan en cuenta el consumo de energía, técnicas de gestión de recursos para optimizar la utilización de los recursos, métodos de seguimiento y medición del consumo energético en microservicios y desarrollo de protocolos de comunicación energéticamente eficientes para microservicios.
El artículo también analiza diversas técnicas y estrategias para mejorar la eficiencia energética en arquitecturas de microservicios, como la optimización de patrones de comunicación, estrategias de asignación de recursos y algoritmos de programación de cargas de trabajo. Finalmente, en el trabajo se expone una descripción general completa del estado actual de la investigación sobre el consumo de energía en arquitecturas de microservicios y destaca la necesidad de realizar más investigaciones en esta área para desarrollar soluciones de microservicios más eficientes energéticamente.

En el trabajo propuesto por (Bharany, 2022 ) se identifica y categoriza los enfoques existentes para mejorar la eficiencia energética en entornos de computación en la nube. Los autores enfatizan en la importancia de adoptar un enfoque múltiple que combine varias técnicas para una eficiencia energética óptima, además destacan la necesidad de seguir investigando tecnologías emergentes como el aprendizaje automático y la inteligencia artificial para la gestión dinámica de la energía en entornos de nube, asi como la necesidad de prácticas sostenibles de computación en la nube para reducir el uso de energía y las emisiones de CO2. En el trabajo se exponen varias técnicas de eficiencia energética a diferentes niveles de gestión de recursos, algoritmos conscientes de la energía, optimización de hardware e infraestructura, integración de energías renovables, gestión de datos, nivel de centro de datos, nivel de red, nivel de software. Además el artículo proporciona una visión general de las técnicas de eficiencia energética existentes en la computación en la nube y la importancia de adoptar un enfoque múltiple que combine varias técnicas para una eficiencia energética óptima. 

(Duarte, 2019) “Model-based Framework for the Analysis of Software Energy Consumption”, exponen algunas preocupaciones sobre el impacto ambiental del desarrollo de software y la necesidad de un diseño de software energéticamente eficiente. Es por ello que los autores proponen un marco de trabajo para analizar el consumo de energía de los sistemas de software utilizando técnicas basadas en modelos. El marco de trabajo tiene como objetivo proporcionar a los desarrolladores e investigadores un enfoque sistemático para comprender y optimizar la eficiencia energética del software El artículo analiza primero la importancia de considerar el consumo de energía en el diseño de software, destacando el impacto del software en el uso general de energía en los sistemas informáticos. Luego presenta el marco propuesto, que consta de cuatro componentes principales: modelos de consumo de energía, modelos de entorno de ejecución, modelos de ejecución de software, técnicas de análisis y optimización. Los autores concluyen que el marco se puede personalizar para diferentes dominios de software y modelos de consumo de energía. Para ello describen la aplicación del marco a un estudio de caso de un algoritmo de clasificación. Los resultados demuestran la capacidad del marco para estimar y comparar el consumo de energía de diferentes implementaciones del algoritmo, lo que puede ayudar a los desarrolladores a identificar cuellos de botella relacionados con el consumo de energía y optimizar el software para mejorar la eficiencia energética. Finalmente, se menciona que el marco propuesto aún está en desarrollo y requiere mayor validación con sistemas de software más grandes y diversos.

(Enes, 2020) en su trabajo abordan el desafío de gestionar eficientemente y optimizar el consumo de energía en clústeres basados en contenedores que ejecutan aplicaciones de big data, donde los costos de energía pueden ser significativos. Principalmente este trabajo se enfoca en garantizar que los contenedores críticos reciban los recursos necesarios y al mismo tiempo minimicen el consumo general de energía en función de sus demandas y prioridades de recursos. Los autores proponen un sistema de presupuesto de energía que permite a los usuarios definir y aplicar un límite de energía para aplicaciones de big data que se ejecutan dentro de un clúster en contenedores. El sistema monitorea el consumo de energía de contenedores individuales y ajusta dinámicamente su asignación de recursos (CPU, memoria) para mantenerse dentro del presupuesto de energía definido. Desde el punto de vista de implementación, el enfoque propuesto utiliza plataformas de orquestación de contenedores existentes tales como Kubernetes donde los beneficios de este tipo de implementaciones permiten obtener una eficiencia energética, al hacer cumplir los límites de energía, el sistema reduce el consumo total de energía de las aplicaciones de big data. El sistema aprovecha las capacidades de limitación de energía definidas por software disponibles en plataformas de hardware modernas para limitar el consumo de energía a nivel de contenedor. Para ello se utilizan técnicas de gestión de recursos, para hacer cumplir los presupuestos de energía, como el escalado dinámico de voltaje y frecuencia y la migración de contenedores.

Para la evaluación, se evalúa el enfoque propuesto a través de experimentos en un clúster que ejecuta aplicaciones de big data, el artículo describe la implementación y evaluación del sistema propuesto utilizando aplicaciones representativas de big data en un clúster de pequeña escala. Los resultados muestran que el enfoque puede reducir eficazmente el consumo de energía sin comprometer el rendimiento de la aplicación. El paper también proporciona información sobre los desafíos de la gestión de energía en clústeres basados en contenedores y propone un enfoque práctico para optimizar el consumo de energía en dichos entornos. Los resultados demuestran la viabilidad del enfoque para hacer cumplir los presupuestos de energía y lograr ahorros de energía significativos sin comprometer el rendimiento de la aplicación.

Además, se logra una gestión dinámica de recursos ya que el sistema ajusta automáticamente la asignación de recursos en función del consumo de energía, lo que garantiza una utilización eficiente de los recursos. Desde el punto de vista de control del usuario, los usuarios pueden definir presupuestos de energía de acuerdo con sus necesidades y objetivos ambientales.Una de las limitaciones del trabajo es que la evaluación se realizó en un entorno limitado y se necesitan más estudios para validar su eficacia en implementaciones a mayor escala. El sistema depende de la disponibilidad de funciones de limitación de energía definidas por software en plataformas de hardware, que pueden no ser universalmente compatibles.

El trabajo propuesto por (Belgaid, 2022) presenta un estudio empírico que analiza el consumo energético de los servicios de software utilizando diferentes lenguajes de programación y prácticas de codificación. El estudio mide el consumo de energía de varios servicios de software que realizan tareas comunes, como el procesamiento de datos y el servicio web, utilizando diferentes lenguajes de programación y estilos de codificación. Con base en los resultados empíricos, en el artículo se propone un conjunto de prácticas de codificación sostenible que los desarrolladores pueden adoptar para reducir el consumo de energía de sus servicios de software. Estas prácticas incluyen la optimización del código para mejorar la eficiencia energética, la minimización del uso de recursos y el uso de bibliotecas y lenguajes de programación energéticamente eficientes. Los autores mencionan que cuando se requiere implementar prácticas para promover un entorno de microservicios más sostenible siempre hay que tener en cuenta optimizar los protocolos de comunicación como utilizar protocolos ligeros y eficientes tales como gRPC o colas de mensajes para minimizar la sobrecarga de la red. Otro de los aspectos a tener en cuenta es implementar tecnologías de contenedorización y sin servidor, por ejemplo utilizar tecnologías de contenedorización como Docker y plataformas sin servidor como AWS Lambda para mejorar la utilización de recursos y las capacidades de escalado automático. Esto permite la asignación de recursos bajo demanda y un menor desperdicio de energía cuando los servicios están inactivos. Finalmente hay que supervisar y optimizar el uso de recursos, supervisando activamente el consumo de recursos de microservicios individuales e implementando estrategias como el escalado horizontal o el escalado automático para optimizar la utilización de recursos, evitando el uso innecesario de recursos y el consumo de energía asociado.

En resumen, los trabajos relacionados ofrecen diversas perspectivas sobre la relación entre los microservicios, sostenibilidad y eficiencia energética. Si bien los microservicios pueden ofrecer algunos beneficios en términos de agilidad y utilización de recursos, también introducen posibles inconvenientes que pueden aumentar el consumo de energía. El impacto general de los microservicios en la eficiencia energética depende de varios factores, como la implementación específica, las características de la carga de trabajo y las estrategias de optimización elegidas. Al ser conscientes de los posibles beneficios y desventajas, las empresas y desarrolladores pueden tomar decisiones informadas y trabajar activamente para crear y promover un entorno de microservicios más sostenible. Para ello se podria implementar tecnologías de contenerización como Docker y plataformas sin servidor como AWS Lambda para mejorar la utilización de recursos y las capacidades de escalamiento automático lo que permite la asignación de recursos bajo demanda y un menor desperdicio de energía cuando los servicios están inactivos y supervisar y optimizar el uso de recursos a través de estrategias como el escalado horizontal o el escalado automático para optimizar la utilización de recursos, evitando el uso innecesario de recursos y el consumo de energía asociado (Jepsen, 2022). Al considerar estos factores e implementar las mejores prácticas, herramientas y marcos de trabajo, las organizaciones pueden aprovechar los beneficios de la arquitectura de microservicios mientras minimizan su impacto ambiental y promueven el desarrollo de software sostenible.

# # Configuración arquitectónica de contenedores para la medición de consumo energético con PowerAPI
La figura expone de forma general el funcionamiento del medidor de potencia de software en PowerAPI, (1) un sensor recopila las métricas sin procesar de la máquina en la que resida las aplicaciones o el software que se desea monitorear en términos de consumo de energía, siendo incompatible una máquina virtual. (2) Las métricas se almacenan en una base de datos para ser utilizadas en un modelo de consumo de energía del software. (3) El modelo de consumo Power Model, utiliza técnicas de aprendizaje automático para estimar el consumo de energía de las aplicaciones o del software con las métricas sin procesar y se calibra a si mismo cuando es necesario. (4) Los valores de las estimaciones producidas por el modelo de consumo se almacenan en otra base de datos. (5) Finalmente, las estimaciones almacenadas en la base de datos se utilizan para optimizar las aplicaciones o el software que se está midiendo.
